{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sujaikarunakaran/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sujaikarunakaran/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'/Users/sujaikarunakaran/Desktop/Assignments/Spring 2020/Ranga/Final Project/Final/RateMds/Phrases_Positive.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive=pd.read_csv(r'/Users/sujaikarunakaran/Desktop/Assignments/Spring 2020/Ranga/Final Project/Final/RateMds/Phrases_Positive.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Sentiment != \"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = df[df.Sentiment == \"Negative\"]\n",
    "df_positive = df[df.Sentiment == \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df[df.Sentiment == \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_negative = df[df_negative]\n",
    "#df_positive = df[df_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=.5,\n",
    "    min_df=10,\n",
    "    max_features=None,\n",
    "    ngram_range=(1, 2),\n",
    "    norm=None,\n",
    "    binary=True,\n",
    "    use_idf=False,\n",
    "    sublinear_tf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctor_names=pd.read_csv(r'/Users/sujaikarunakaran/Desktop/Assignments/Spring 2020/Ranga/Final Project/doctor_names_ratemds.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = doctor_names[\"first_names\"].to_list()\n",
    "middle_names = doctor_names[\"midle_names\"].to_list()\n",
    "last_names = doctor_names[\"last_names\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = [x for x in first_names if str(x) != 'nan']\n",
    "middle_names = [x for x in middle_names if str(x) != 'nan']\n",
    "last_names = [x for x in last_names if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = first_names + middle_names + last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(['dr', 'Dr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(['doctor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(['dr', 'shashoua', 'great', 'drachler', 'excellent', 'brilliant', 'terrible', 'awful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.extend(['roth', 'ramsey', 'bodner', 'ob_gyn', 'absolutely', 'recommend', 'Roth'])\n",
    "stop_words.extend(['Lipowich', 'lipowich', 'gyne-oncologist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21137 entries, 0 to 21136\n",
      "Data columns (total 3 columns):\n",
      "Doc_names         21137 non-null object\n",
      "Review_phrases    21137 non-null object\n",
      "Sentiment         21137 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 495.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_positive.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = list(sent_to_words(df['Review_phrases']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(df['Review_phrases'], min_count=5, threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-17a528472f11>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-17a528472f11>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(bigram_mod[df_negative['Review_phrases'])\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(bigram_mod[df_negative['Review_phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].map(lambda x: x.lstrip(\"\\''\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].map(lambda x: x.lstrip(\"%\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].map(lambda x: x.strip(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].map(lambda x: x.strip(')('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].map(lambda x: x.strip('\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = df['Review_phrases'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    he is simply the best\n",
       "1                           drachler is very knowledgeable\n",
       "2                   his bedside manners are simply perfect\n",
       "3         drachler is an excellent example of how a phy...\n",
       "4                                        'it was my first \n",
       "5         michael drachler is god-sent directly from he...\n",
       "6                                               competent \n",
       "7                                  i trust him completely \n",
       "8                                         drachler greatly\n",
       "9         he not only loves to bring new life into the ...\n",
       "10                                          to be healthy \n",
       "11                         drachler is truly one of a kind\n",
       "12                           she was pregnant within  days\n",
       "13                                 drachler is very caring\n",
       "14              will not end the visit until you are ready\n",
       "15        drachler is one of the best doctors i have ev...\n",
       "16         as you know most doctors see you for - minutes \n",
       "17                      drachler spent with us  whole hour\n",
       "18                    i was very impressed with no rushing\n",
       "19                        especially his positive attitude\n",
       "20                                 he is the absolute best\n",
       "21                                                    more\n",
       "22        then you have to hunt for someone to replace ...\n",
       "23                   you could not choose a more wonderful\n",
       "24           i have been a patient of hers for many years \n",
       "25          'she was my doctor through my first pregnancy \n",
       "26                                         some unexpected\n",
       "27                                           she was kind \n",
       "28                 confident throughout the entire process\n",
       "29                        she delivered my lb baby calmly \n",
       "                               ...                        \n",
       "21107            on the doorknob ready to leave as my husb\n",
       "21108     the only thing what caught his attention was ...\n",
       "21109                      \"my ratings may not be accurate\n",
       "21110     none of these categories outweigh my true exp...\n",
       "21111                                feel comfortable with\n",
       "21112               he comments more about your appearance\n",
       "21113                          he has a great office staff\n",
       "21114                                           'very kind\n",
       "21115                                                 nice\n",
       "21116    [\"many years ago i went in for a routine  week...\n",
       "21117     without being asked she decided to strip my m...\n",
       "21118     my three other children were full term weighi...\n",
       "21119                                          he is fine \n",
       "21120                                 healthy years later \n",
       "21121     i forgot to mention that she also did the sam...\n",
       "21122                           both high risk pregnancies\n",
       "21123                                she is a wonderful dr\n",
       "21124               glad i was strong to listen to myself \n",
       "21125          happy not to have the un-necessary surgery \n",
       "21126                                  have a wonderful dr\n",
       "21127                   'she delivered my first two babies\n",
       "21128                                 she\\'s a good doctor\n",
       "21129                             she gets very exciteable\n",
       "21130              i found a much calmer doctor after that\n",
       "21131                                        \"fantastic dr\n",
       "21132                           both high risk pregnancies\n",
       "21133                                   very knowledgeable\n",
       "21134     'during my visit i felt that i was treated ve...\n",
       "21135    i would absolutely recommend this doctor to my...\n",
       "21136             i felt this visit was an amazing success\n",
       "Name: Review_phrases, Length: 21137, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    for doc in text:\n",
    "        review_words = \"\"\n",
    "        if doc not in stop_words:\n",
    "            review_words = doc\n",
    "        return review_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = remove_stopwords(df['Review_phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = remove_stopwords([\"He pushes his appoints back sometimes as much as 2 hours\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases'] = make_bigrams(df['Review_phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive['review_removed'] = lemmatization(df_positive['review_removed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive[\"Review_phrases\"] = remove_stopwords(df_positive[\"Review_phrases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive[\"Review_phrases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texts'] = [', '.join(map(str, l)) for l in df['Review_phrases']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative = df[df.Sentiment == \"Negative\"]\n",
    "df_positive = df[df.Sentiment == \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229\n"
     ]
    }
   ],
   "source": [
    "vectorizer = vectorizer.fit(df['texts'])\n",
    "tfidf = vectorizer.transform(df['texts'])\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install corextopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corextopic import corextopic as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = []\n",
    "model = ct.Corex(n_hidden=7, seed=42)\n",
    "model = model.fit(\n",
    "    tfidf,\n",
    "    words=vocab\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: feel, comfortable, feel comfortable, sure, makes, questions, made, make, made feel, make sure, makes feel, answer, easy talk, makes sure, things, answer questions, made sure, feel like, always, talk\n",
      "Topic #2: time, pregnant, get, appointment, wait, first time, weeks, felt, took, see, back, minutes, went, much, told, takes, months, call, day, times\n",
      "Topic #3: ever, best, would highly, highly, best ever, would, one best, highly recommended, recommended, anyone, bed_side, one, best ob_gyn, highly anyone, best doctors, ob_gyn, bed_side manner, far best, obgyn, ever seen\n",
      "Topic #4: first, baby, pregnancy, delivered, child, years, new, many, first pregnancy, first child, healthy, many years, first visit, deliver, high_risk, delivered first, son, first baby, ob, delivering\n",
      "Topic #5: staff, office staff, office, friendly, staff friendly, humor, sense, nice, sense humor, staff wonderful, staff always, staff also, also, staff nice, staff amazing, good experience, always friendly, really nice, nursing, nursing staff\n",
      "Topic #6: like, better, could, really, know, going, another, said, ask, surgery, right, find, want, wish, doctors, available, someone\n",
      "Topic #7: patients, cares, care, really cares, cares patients, health, best care, listens, genuinely, care patients, really listens, many patients, interest, blood_pressure, seems, level, best gynecologist, trust, really care, time patients\n"
     ]
    }
   ],
   "source": [
    "for i, topic_ngrams in enumerate(model.get_topics(n_words=20)):\n",
    "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
    "    print(\"Topic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow=pd.read_csv(r'/Users/sujaikarunakaran/Desktop/Assignments/Spring 2020/Ranga/Final Project/Final/RateMds/Buckets_ v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_expertise = bow[\"Medical Expertise\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedside_manners = bow[\"Bedside Manners\"].to_list()\n",
    "office_staff = bow[\"Staff\"].to_list()\n",
    "costs = bow[\"Costs/Expenses\"].to_list()\n",
    "clinic_envt = bow[\"Office Environment\"].to_list()\n",
    "ease_schedule = bow[\"Ease of Appointment\"].to_list()\n",
    "waiting_time = bow[\"Waiting Time\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_management = office_staff + costs + clinic_envt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanedList = [x for x in countries if str(x) != 'nan']\n",
    "bedside_manners = [x for x in bedside_manners if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_staff = [x for x in office_staff if str(x) != 'nan']\n",
    "costs = [x for x in costs if str(x) != 'nan']\n",
    "clinic_envt = [x for x in clinic_envt if str(x) != 'nan']\n",
    "ease_schedule = [x for x in ease_schedule if str(x) != 'nan']\n",
    "waiting_time = [x for x in waiting_time if str(x) != 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs.extend([\"pay\", \"amount\", \"bill\", \"billing\", \"cash\", \"charge\", \"charging\", \"insurance\", \"medicaid\", \"medic\", \"aid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = med_expertise, bedside_manners, office_staff, costs, clinic_envt, ease_schedule, waiting_time\n",
    "#anchors = med_expertise, bedside_manners, office_management, ease_schedule, waiting_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedside_manners.extend([\"bedside_manner\", \"rude\", \"bedside_manners\", \"bedside\", \"manners\", \"manner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors = [\n",
    "    [a for a in topic if a in vocab]\n",
    "    for topic in anchors\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ct.Corex(n_hidden=7, seed=42)\n",
    "model = model.fit(\n",
    "    tfidf,\n",
    "    words=vocab,\n",
    "    anchors=anchors, # Pass the anchors in here\n",
    "    anchor_strength=50 # Tell the model how much it should rely on the anchors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1: pregnant, knowledgeable, able, practice, child, delivered, surgery, delivery, health, job, issues, work, medical, birth, life, section, labor, deliver, knowledge, exam, check, options, delivering, test, ultrasound, pregnancies, field, decision, treatment, complications\n",
      "Topic #2: time, feel, care, comfortable, amazing, patient, questions, bedside_manner, talk, willing, pleasant, help, answer, gentle, attentive, unprofessional, concerns, manner, confident, listen, answers, explain, bed_side, respectful, explains, question, answered, explained, informative, special\n",
      "Topic #3: staff, nurse, nurses, information, service, nursing, team, front, dealing, assistant, staff friendly, staff wonderful, staff always, staff also, staff nice, staff amazing, nursing staff, also, nice, staff awesome, staff helpful, wonderful staff, friendly staff, staff kind, staff well, also friendly, staff best, wonderful, always friendly, well\n",
      "Topic #4: insurance, pay, rate, paid, amount, bill, charge, billing, amount time, full, attention, high, money, higher, unless, visit, overall, dont, chose, calling, different, giving, heart, lost, already, self, except, mistake, go back, whether\n",
      "Topic #5: office, far, hospital, area, clean, clinic, drive, city, offices, center, office staff, far best, new office, far away, love office, doctors office, away, new, stay, along, run, live, leave, moved, doctors, contact, close, tried, even_though, everyone\n",
      "Topic #6: appointment, busy, appointments, called, schedule, ease, phone, appt, calls, receptionist, scheduled, routine, first appointment, get appointment, get, feel ease, make appointment, day, even, call, scheduling, right_away, easy get, put, puts, morning, prior, past, back, set\n",
      "Topic #7: wait, early, quick, minutes, available, room, fast, long, visits, hour, waiting, waited, minute, short, late, punctual, worth wait, worth, always available, wait time, wait minutes, waiting_room, hours, exam room, wait hour, well worth, times, see, longer, min\n"
     ]
    }
   ],
   "source": [
    "for i, topic_ngrams in enumerate(model.get_topics(n_words=30)):\n",
    "    topic_ngrams = [ngram[0] for ngram in topic_ngrams if ngram[1] > 0]\n",
    "    print(\"Topic #{}: {}\".format(i+1, \", \".join(topic_ngrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_positive.drop(['topic_1', 'topic_2', 'topic_3', 'topic_4', 'topic_5', 'topic_6', 'topic_7'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = pd.DataFrame(\n",
    "    model.transform(tfidf), \n",
    "    columns=[\"topic_{}\".format(i+1) for i in range(7)]\n",
    ").astype(float)\n",
    "topic_df.index = df_negative.index\n",
    "df_negative = pd.concat([df_negative, topic_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative.sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_negative.rename(columns={'topic_1': 'med_expertise_neg', 'topic_2':'bedside_manners_neg', 'topic_3':'office_staff_neg', 'topic_4':'costs_neg', 'topic_5':'clinic_envt_neg', 'topic_6':'ease_schedule_neg', 'topic_7':'waiting_time_neg'})\n",
    "                              \n",
    "                              \n",
    "                              \n",
    "                              \n",
    "                              \n",
    "                              \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(r'/Users/sujaikarunakaran/Desktop/Assignments/Spring 2020/Ranga/Final Project/Final/Healthgrades/Negative Phrases/Negative_AS8_NW30.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################Labelled LDA############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(r'/Users/sujaikarunakaran/Downloads/Phrase_with_Sentiment_V1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive = df_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative = df_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_negative['Review_phrases'] = df1_negative['Review_phrases'].map(lambda x: x.strip('\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases'] = df1_positive['Review_phrases'].map(lambda x: x.strip(\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases'] = df1_positive['Review_phrases'].map(lambda x: x.strip('][)('))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases'] = df1_positive['Review_phrases'].map(lambda x: x.strip(\"\\''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases'] = df1_positive['Review_phrases'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases'] = df1_positive['Review_phrases'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(df1_positive['Review_phrases'], min_count=5, threshold=100) \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['Review_phrases'] = list(sent_to_words(df1_positive['Review_phrases']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['review_removed'] = remove_stopwords(df1_positive['Review_phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['review_removed'] = make_bigrams(df1_positive['review_removed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_positive['review_removed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(df1_positive['Review_phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df1_positive['Review_phrases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=7, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df1_positive['Review_phrases'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/Users/sujaikarunakaran/Downloads/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=df1_positive['review_removed'], dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=df1_positive['review_removed'], start=2, limit=40, step=6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
